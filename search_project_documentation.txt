High level goal:
High level is the goal to build web based search tool that enables vector search over books. The target user is
currently people like my girlfriend -- fantasy / sci-fi readers.

Core components:
1. Chunking the book into smaller parts for embedding model to process including some metadata (chunk index).
2. Embedding the books.
3. Vector search user query (retrieve top K chunks).
4. LLM refinement (using top K chunks + query) to select the single best chunk.
---
5. Web application (Flask + HTML/CSS/JS) for user interface.
6. Feedback mechanism (thumbs up/down on results, saved to JSON).
---
7. Hosting for the website.

---------
Manual Chunker (`manual_chunker.py`):
This script processes a PDF book file specified in its configuration (currently hardcoded list).
It extracts all text content using `pdfplumber`.
The text is cleaned (excessive newlines/spaces removed).
It uses `langchain` and `tiktoken` (v0.9.0+) to split text into chunks (target size, overlap).
For each chunk, it saves its index (0-based) and text.
The output is a JSON file per book (e.g., `Promise of Blood_full.json`).
Each entry contains: `book_name` (derived from filename), `chunk_index`, `text`.
Note: Input file handling could be made more dynamic (e.g., command-line args).

---
Embed Chunks (`embed_chunks.py`):
This script generates vector embeddings for book chunks using the Cohere API (v5.x, `ClientV2`).
It processes output JSON from the chunker (hardcoded list of `*_full.json` files).
It loads the Cohere API key from `.env`.
Initializes the Cohere client.
Loads chunked data, extracts texts, batches them, and generates embeddings (`embed-v4.0`, float).
Combines original chunk data (index, text) with the generated embedding vector.
Saves the combined data to a new output JSON file per book (e.g., `promise_of_blood_embeded.json`).
The structure for each entry is: `book_name`, `chunk_index`, `text`, `embedding`.
Note: Input file handling could be made more dynamic.

---
Search Chunks (`search_chunks.py`):
This script provides the asynchronous `search_book_chunks` function used by the web application.
It now supports searching across *multiple* selected books using a concurrent, two-stage
LLM refinement process.

Stage 1: Concurrent Refinement per Book
- Takes user query and a *list* of paths to selected books' embedding files.
- Loads Cohere and DeepSeek API keys from `.env`.
- Creates per-request asynchronous clients for Cohere (`AsyncClient`) and DeepSeek (`AsyncOpenAI`) using `async with` for proper cleanup.
- **Concurrently** for each selected book (`asyncio.gather`):
    - Loads only that book's embedding data.
    - Generates a query embedding (async Cohere).
    - Performs vector search (dot product) to find the top N (default 15) semantic matches.
    - Loads the *full text* for these top N chunks from the corresponding `chunks_json/` file.
    - Sends the query and formatted top N chunk *texts* to the DeepSeek chat model (async).
    - Prompts the LLM for step-by-step reasoning and selection of the single best `chunk_index`
      *for that specific book*.
    - Parses the LLM response robustly (handles `None`, errors). If LLM fails/selects `None`,
      it falls back to the top semantic result (rank 0) for that book.
    - Stores the data dictionary of the selected candidate chunk (book name, chunk index, text
      from embedding file, score, rank within the book's semantic results).

Stage 2: Final Aggregation and Refinement (if >1 book searched)
- Collects the best candidate data dictionaries from all successful Stage 1 tasks.
- If only one book was searched, its Stage 1 result is returned directly.
- If multiple candidates exist:
    - Loads the *full text* for each candidate chunk from its respective `chunks_json/` file.
    - Creates a new prompt containing the original user query and the texts of all candidate
      chunks (clearly identified by book and index).
    - Sends this combined prompt to the DeepSeek chat model in a *single*, final async call.
    - Prompts the LLM to select the *overall best* candidate chunk from the provided list.
    - Parses the response. If the LLM fails or provides an invalid choice, it falls back to the
      candidate that had the best rank (and score as tie-breaker) from Stage 1.

Output:
- Returns a list containing the single data dictionary for the final selected chunk.
- This dictionary includes `book_name`, `chunk_index`, `text` (from the embedding file),
  `score` (from Stage 1 semantic search), and `rank` (from Stage 1 semantic search).
- **Important**: `app.py` uses the returned `book_name` and `chunk_index` to load the actual
  display text from the corresponding `chunks_json/` file.
- Includes improved error handling for API calls (checks response structure, logs HTML errors).
- Clears and writes to `last_llm_output.txt` at the start of each
  `search_book_chunks` call, recording only the LLM outputs for the latest query.
- Appends all raw LLM responses to `last_llm_output.txt`, including Stage 1 per-book
  responses (with book name and query context) and the final Stage 2 response.

---
Web Application (`app.py` & `templates/index.html`):
The web application uses Flask (with `async` support enabled) to serve a single-page interface.
Key features:
- Header with application title.
- Dynamic Book Selection: Buttons are generated via JavaScript based on `*_embeded.json` files found
  in the `embedded_books/` directory.
- Search Bar & Button: Input field for queries and an explicit Search button. These are disabled
  until a book is selected.
- Book Selection Prompt: A message prompts the user to select a book if none is active.
- Search Trigger: Search is initiated by pressing Enter in the input field or clicking the button.
- Loading Indicator: A spinner and text appear while the backend processes the search.
- Result Display & Navigation:
    - Shows the single text chunk returned by the backend.
    - The backend (`app.py` /search route) takes the `chunk_index` from `search_chunks`, reads
      the text from the corresponding file in `chunks_json/`, and sends this text and the total
      chunk count for the book to the frontend.
    - "Previous Chunk" and "Next Chunk" buttons appear below the result text.
    - Clicking these buttons calls a new backend endpoint (`/get_chunk_text`) to fetch and display
      the text of the adjacent chunk without running a new search.
    - Buttons are disabled at the start/end of the book.
    - **Clipboard Copy Button:** A clipboard icon button appears at the top right of the chunk
      text box in the result card. Clicking this button copies the currently displayed chunk text
      to the user's clipboard. A small tooltip appears near the button to confirm the text was
      copied successfully.
    - **Search Timer:** After each search, the elapsed time (in seconds) is displayed to the right
      of the feedback buttons in the top Result heading. The timer is cleared when a new search
      starts or if an error occurs.
- Feedback:
    - Solid thumbs up/down buttons appear next to the main "Result" heading when a result is shown.
    - Clicking either button sends the current `query`, `book_filename`, `chunk_index`, and
      correctness (true/false) to the backend `/feedback` endpoint.
    - The buttons become disabled, visually change color, and are replaced by a "Feedback Sent!"
      message after a short delay.

Backend (`app.py`):
- Serves the main `index.html` page, passing the list of available books.
- Provides an *asynchronous* `/search` endpoint (POST) (`async def search`):
    - Receives the `query` and a *list* of selected `book_filenames`.
    - Logs the search query and selected books list to `all_queries.json`.
    - Validates input and constructs full paths to the embedding files.
    - Calls and *awaits* the `search_book_chunks` async function from `search_chunks.py`.
    - Takes the single result dictionary returned by the search function.
    - **Crucially**, uses the returned `book_name` and `chunk_index` to open the corresponding
      original chunk file in `chunks_json/` and reads the `text` field from that file.
    - Creates a new result dictionary containing this text from `chunks_json/` and other relevant
      metadata (`chunk_index`, `score`, `rank`, `total_chunks` for that book).
    - Returns this final result data as JSON to the frontend.
    - Includes basic logging and error handling.

- Provides a `/get_chunk_text` endpoint (POST) that:
    - Receives `book_filename` (of the currently displayed result) and `chunk_index`.
    - Reads the specified chunk's text from the corresponding `chunks_json/` file.
    - Returns the chunk data (text, index) as JSON.

- Provides a `/feedback` endpoint (POST) that:
  - Receives `query`, `selected_books` (list), `chunk_index`, `is_correct`, and `rank` as JSON.
  - The `rank` represents the 0-based position of the displayed chunk within the initial top N
    semantic search results before LLM refinement.
  - Validates the input data, including checking that `rank` is null or a non-negative integer.
  - Loads existing feedback data from `feedback_data.json`.
  - Appends the new feedback entry (including the `rank`) to the list.
  - Saves the updated list back to `feedback_data.json`.
  - Returns a success message.

Frontend (`index.html` JavaScript):
- Dynamically creates book selection buttons based on data passed from Flask.
- Handles book selection state (only one active), updates search bar placeholder, enables/disables
  search input/button, and shows/hides the 'Select Book' prompt.
- Contains `triggerSearch` function called on Enter/button click:
    - Validates that a book is selected and a query exists.
    - Shows loading indicator, disables inputs.
    - Sends `query` and `book_filename` to the `/search` backend endpoint using `fetch`.
    - Calls `displayResults` with the response.
    - Hides loading indicator, re-enables inputs in a `finally` block.
- Contains `displayResults` function:
    - Clears previous results/loading indicator.
    - Handles 'No results found' or error messages.
    - Clones a hidden HTML template for the result card.
    - Populates the card with the text, book title, and chunk index.
    - Initializes state for navigation: remembers the original chunk index (`originalChunkIndex`)
      and resets a cache for full chunk text (`chunkFullTextCache`). Stores the initial `rank`
      received from the backend in `currentRank`. The original chunk's full text is added to the cache.
    - Shows the global feedback buttons next to the "Result" heading.
    - Appends the card to the results area.
    - Sets up event listeners for the "Previous Chunk" and "Next Chunk" buttons, enabling/
      disabling them based on the current index and total chunk count.

- Contains `getFullChunkText` helper async function:
    - Checks if the requested chunk index's full text is already in `chunkFullTextCache`.
    - If cached, returns the cached text.
    - If not cached, calls the `/get_chunk_text` endpoint to fetch the full text.
    - Stores the fetched full text in the cache before returning it.

- Contains `fetchChunkText` async function:
    - Called by navigation buttons ('previous' or 'next').
    - Uses `getFullChunkText` to retrieve the full text of the target chunk.
    - Implements specific overlap trimming logic:
        - If the target chunk *is* the `originalChunkIndex`, its full text is always displayed.
        - If navigating 'next' (from N to N+1), uses `getFullChunkText` to get chunk N's text
          and displays chunk N+1 after removing overlap: `removeOverlap(textN, textN+1)`.
        - If navigating 'previous' (from N to N-1), uses `getFullChunkText` to get chunk N-2's
          text and displays chunk N-1 after removing overlap: `removeOverlap(textN-2, textN-1)`.
    - Updates the result card content with the (potentially trimmed) text and target index.
    - Updates the `currentChunkIndex` and stores the *full* target text in `currentFullChunkText`.
    - Updates the navigation button states.

- Contains global feedback button listeners (setup on page load):
    - Added to the thumbs up/down buttons next to the "Result" heading.
    - When clicked, call the `sendFeedback` function.

- Contains `sendFeedback` async function:
  - Reads current `query`, `chunk_index`, `book_filename`, and `rank` from the page state.
  - Sends a POST request with this data (including `rank`) to the `/feedback` endpoint.
  - Handles the response and potential errors, updating the UI (disabling buttons, showing message).

- Contains clipboard copy logic:
    - Each result card includes a clipboard icon button at the top right of the chunk text box.
    - When clicked, this button copies the currently displayed chunk text to the clipboard using
      the browser's clipboard API.
    - A tooltip appears briefly to confirm the copy action, providing user feedback.

- Contains search timer logic:
    - When a search is triggered, the timer starts.
    - When results are displayed, the timer stops and the elapsed time (in seconds) is shown in
      the UI next to the feedback buttons in the Result heading.
    - The timer is cleared on new search or error.

Dependencies are managed through `requirements.txt` (including `